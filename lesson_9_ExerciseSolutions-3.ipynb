{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linear regression, part 1\n",
    "\n",
    "The method of regression is one of the oldest and most widely used analytics methods. The goal of regression is to produce a model that represents the ‘best fit’ to some observed data. Typically the model is a function describing some type of curve (lines, parabolas, etc.) that is determined by a set of parameters (e.g., slope and intercept). “Best fit” means that there is an optimal set of parameters according to an evaluation criteria we choose.\n",
    "\n",
    "A regression model attempts to predict the value of one variable, usually known as the **dependent variable**, **response variable** (**target** or **label** in ML linguo), using the values of other variables, known as **independent variables**, **explanatory variables**, or **covariates** (**features** in ML linguo). Linear regression is the foundational form of regression, which includes a broader set of models. To solve linear regression, normally the **method of least squares** is used.  Here, we are looking to find parameters of the function that minimizes the square of the error between the predictions, which are the function output, and the observed target values. These errors are also called **residuals**. Note that the word **regression** refers to a larger family of models in statistics including linear and logistic regression, whereas in the ML community it usually refers to training a supervised learning algorithm on a data set with a **numeric target**, as oppsed to **classificaiton** where the target is categorical. So we need to know from context which is being referred to."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib\n",
    "matplotlib.rcParams['figure.figsize'] = [10, 7]\n",
    "import scipy.stats as stats\n",
    "import matplotlib.pyplot as plt\n",
    "import statsmodels.api as statsmodels\n",
    "import statsmodels.formula.api as sm\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error, r2_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "beta_0 = -3 # the intercept\n",
    "beta_1 = 8 # the slope\n",
    "\n",
    "x_data = np.random.uniform(0, 1, size = 200)\n",
    "error = np.random.normal(0, 1, size = 200)\n",
    "y_data = beta_0 + beta_1 * x_data + error\n",
    "\n",
    "sns.scatterplot(x = x_data, y = y_data)\n",
    "sns.lineplot(x = x_data, y = beta_0 + beta_1 * x_data, color = 'red');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see, the data above was generated using $\\beta_0 = -3$ (the intercept term) and $\\beta_1 = 8$ (the slope). The terms $\\beta_0$ and $\\beta_1$ are the population parameters which linear tries to estimate. In other words, it tries to find $b_0$ and $b_1$ that are **estimates** for $\\beta_0$ and $\\beta_1$. \n",
    "\n",
    "The word **estimate** refers to the fact that $b_0$ and $b_1$ are derived from a sample. Here we are simulating data, so In real life, unless we simulate the data like we did above, we don't know $\\beta_0$ and $\\beta_1$. In fact, in practice, we aren't even sure if the relationship is between $X$ and $Y$ is best described as an equation like $Y = \\beta_0 + \\beta_1 X + \\text{error}$ in linear regression (or some other equation using another equation-based algorithm) or even a **rule-based** model like tree-based models. A simple rule-based model would say something like this:\n",
    "\n",
    "$$\n",
    "\\begin{equation*}\n",
    "\\hat Y = \\begin{cases}\n",
    "             -1  & \\text{if } x < 0.5 \\\\\n",
    "              2  & \\text{if } x \\ge 0.5\n",
    "     \\end{cases} \\quad\n",
    "\\end{equation*}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.scatterplot(x = x_data, y = y_data)\n",
    "sns.lineplot(x = [0, 0.5], y = [-1, -1], drawstyle = 'steps', color = 'red')\n",
    "sns.lineplot(x = [0.5, 1], y = [2, 2], drawstyle = 'steps', color = 'red');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Of course, a rule like the above can also be written as an equation and the distinction between rule-based and equation-based algorithms is not that important in practice. The above example suggests that our rule-based model would do a poor job compared to the equation-based one. But rule-based algorithms have their advantages too. For example, they can do better when we have lots of categorical variable and they make fewer assumptions about the data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training models in Python\n",
    "\n",
    "Now, you are ready to build and evaluate the model using Python. Python has libraries that contain linear modeling capabilities. The first python library that is popular for linear regression is `sklearn`, which contains many other machine learning algorithms besides linear regression. The second library is called `statsmodels`.  For those that have experience with the programming language, R, this library is the most similar because it provides easy statistical analysis of linear models that are fitted to the data. To start, we will show how to use the `sklearn` for linear regression.\n",
    "\n",
    "If we have a single feature like we do here, we have to reshape the data first so every data point (row) is itself an array."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = x_data.reshape(-1, 1)\n",
    "y = y_data.reshape(-1, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now train a linear regression model on the data and then get predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "regression_model = LinearRegression() # initialize model\n",
    "regression_model.fit(x, y)  # fit (or train) a model\n",
    "y_pred = regression_model.predict(x) # predict using a model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here's how we can extract the coefficients, i.e. **intercept** $a$ and **slope** $b$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('intercept:', regression_model.intercept_)\n",
    "print('slope:' ,regression_model.coef_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that $a$ and $b$ are close to $\\alpha$ and $\\beta$. We can also derive the **root mean squared error** $\\text{RMSE}$ and the **coefficient of determination** $R^2$ for the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rmse = mean_squared_error(y, y_pred, squared = False) # obtain RMSE\n",
    "r2 = r2_score(y, y_pred) # obtain R^2\n",
    "print('RMSE: ', rmse)\n",
    "print('R^2 score: ', r2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise\n",
    "\n",
    "- Instead of plotting $X$ against $Y$, plot $X$ against $Y - \\hat Y$ which is the residual. In statistics, we often use the **hat notation** to indicate something is a predicted value. It's also useful to draw a horizontal line at zero residuals to see the center of the data. HINT: Don't forget to use `reshape` if you need to flatten the array."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## your code goes here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It's important to look at the residual plot because if the model did a good job capturing the trend in the data, then what remains (the residuals) should look random. If the residuals don't look random, there maybe room for more complex models. Here's an example: Let's say the true relationship beween $X$ and $Y$ is now a curved one like the one described here:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "beta_0 = -3 # the intercept\n",
    "beta_1 = 8 # the slope\n",
    "beta_2 = 8\n",
    "\n",
    "x_data = np.random.uniform(0, 1, size = 200)\n",
    "error = np.random.normal(0, 1, size = 200)\n",
    "y_data = beta_0 + beta_1 * x_data + beta_2 * x_data**2 + error\n",
    "\n",
    "sns.scatterplot(x = x_data, y = y_data);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Ignore the curved line for now and just fit a straight line anyway. Then plot the above scatterplot and plot the line."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = x_data.reshape(-1, 1)\n",
    "y = y_data.reshape(-1, 1)\n",
    "\n",
    "## your code goes here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Try to picture what the residual plot will look like based on the scatter plot above. Then plot the residual plot and confirm your intuition."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## your code goes here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Now plot the distribution of the residuals, which is another graphic we often look at. Is the same tendency we observed above also visible in the distribution of the residuals?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## your code goes here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A residual plot like the above suggests the model is **biased**. We can see for example that when $X$ is in the $(0, 2)$ range, the model's predictions are consistantly higher than the observed values for $Y$. This means that after fitting a straight line, there's still *information* about the true relationship between $X$ and $Y$ that we've left on the table. In other words, the line wasn't completely useless, but it wasn't enough either.\n",
    "\n",
    "- Fit a new model to the data that includes the original feature $X$, but also a new feature $X^2$. Note that we are calling the feature $X^2$ to call out the obvious: that it can be directly obtained from $X$ by squaring it, but it could have been any other feature $Z$ with any relationship to $X$ or none at all. HINT: To train a model with two features, we need to combine $X$ and $X^2$ into a single array, which we can do using `X = np.concatenate([x, x**2], axis = 1)`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## your code goes here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Examine the scatter plot and the trend line of the new model. Does the model seem like a good fit?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## your code goes here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What we did above is sometimes referred to as **polynomial regression**, because by adding polynomial terms like $X^2$ we can add non-linearity to the relationship between $X$ and $Y$. \n",
    "\n",
    "**IMPORTANT:** Polynomial regression is still considered **linear regression**. This is because the word **linear** in linear regression means linear *in the parameters*, not in the features. So transformations of features are allowed, as long as we preserve linearity in the parameters. For example here's another linear regression model:\n",
    "\n",
    "$$\\log(Y) = \\beta_0 + \\beta_1 \\log(X_1) + \\beta_2 X_1^2 + \\text{error}$$\n",
    "\n",
    "And here's a model that is not linear in the parameters:\n",
    "\n",
    "$$Y = \\beta_0 + \\frac{\\beta_1 X_1}{\\beta_2 \\exp(X_1)} + \\text{error}$$\n",
    "\n",
    "Sometimes we can turn a non-linear model into a linear model by applying the right transformation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### End of exercise"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's now go back to the data that we started with initially."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "beta_0 = -3 # the intercept\n",
    "beta_1 = 8 # the slope\n",
    "\n",
    "x_data = np.random.uniform(0, 1, size = 200)\n",
    "error = np.random.normal(0, 1, size = 200)\n",
    "y_data = beta_0 + beta_1 * x_data + error\n",
    "\n",
    "sns.scatterplot(x = x_data, y = y_data)\n",
    "sns.lineplot(x = x_data, y = beta_0 + beta_1 * x_data, color = 'red');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that this time we took $X$ and $Y$ and stored them into a `DataFrame`. This is because we now want to show how to fit a line with the `statsmodels` package. The model declaration and fitting follow a different format and unlike `sklearn` which works with the original `numpy` array objects, with `statsmodel` using a `DataFrame` simplifies things. \n",
    "\n",
    "The model we train below uses `ols` which stands for **ordinary least squares**, which is a fancy term for linear regression. Yes, the field of statistics and machine learning is full of redundant terminology!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sim_data = pd.DataFrame({'x': x_data, 'y': y_data})\n",
    "\n",
    "ols_model = sm.ols(formula = 'y ~ x', data = sim_data)\n",
    "ols_model = ols_model.fit() # fit the model\n",
    "\n",
    "print('Intercept: {0:.5f}'.format(ols_model.params.Intercept))\n",
    "print('Slope : {0:.5f}'.format(ols_model.params.x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sim_data['y_pred'] = ols_model.predict(sim_data)\n",
    "sim_data['resid'] = sim_data['y'] - sim_data['y_pred']\n",
    "sim_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Interpreting the coefficients\n",
    "\n",
    "It is very important to know how to interpret the model's coefficients:\n",
    "- The **intercept** is the average value of $Y$ when x is zero. This can have a good interpretation as long as $X = 0$ makes sense. For example, if $X$ is age and $Y$ is height, then the interpect is your height at birth.\n",
    "- The **slope** is the change in $Y$ we should expect to see **on average**, if we increase $X$ by 1 unit. So in our example, the slop is how much you grow by on average as you get a year older. A negative slope corresponds to a decrease and a positive slop an increase in $Y$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "ols_model = sm.ols(formula = 'y ~ x', data = sim_data)\n",
    "ols_model = ols_model.fit()\n",
    "print('Intercept = {:6.2f}, Slope = {:6.2f}'.format(*ols_model.params))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise\n",
    "\n",
    "The interpretation of the interpect doesn't change with many features, but the interpretation of the slope gets a little more involved if we have more than one feature. Let's say for example that we have features $X_1$ and $X_2$. Then the model is\n",
    "\n",
    "$$Y = \\beta_0 + \\beta_1 X_1 + \\beta_2 X_2 + \\text{error}$$\n",
    "\n",
    "The model we fit will be an estimate of the above model:\n",
    "\n",
    "$$\\hat Y = b_0 + b_1 X_1 + b_2 X_2$$\n",
    "\n",
    "where the **parameters** $\\beta_i$ are replaced with **statistics** $b_i$. In the context of regression we refer to these statistics more commonly as **coefficients**. Note that to avoid clutter, we dropped the row index from all the notation we use in this notebook. So $\\hat Y = b_0 + b_1 X_1 + b_2 X_2$ should really read as \n",
    "\n",
    "$$\\hat Y^{(j)} = b_0 + b_1 X_1^{(j)} + b_2 X_2^{(j)}$$ \n",
    "\n",
    "for all rows $j = 1, \\cdots, n$, but since this is clear from context, it's easier to drop the row index. This also applied to any summation we use in the notebook without an index.\n",
    "\n",
    "- Go over the interpretaion of the **intercept** and **slope** and apply them to the context of having two features. Do you think the inerpretations are still valid? If not, how would you refrase them to make them more exact.\n",
    "\n",
    "- The `statsmodel` library has the advantage of giving us statisical summaries and diagnostic plots. Many of these statistics can be obtained directly by calling the `summary` method. Examine the results below. Where the intercept and slope are listed, you will find their values as well a a P-value. Based on what you know about hypothesis testing what do you think the null and alternative hypotheses are in this case, and what conclusion do we draw from the p-values?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(ols_model.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### End of exercise"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's get the TSS, ESS and RSS for the fitted model. Since the derivations are straight-forward, we can just manually calculate them. For the RMSE, we refer to the `ols_model` object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = sim_data['y']\n",
    "y_bar = np.mean(y)\n",
    "y_pred = ols_model.predict(sim_data['x'])\n",
    "\n",
    "TSS = np.sum((y - y_bar)**2)\n",
    "RSS = np.sum((y - y_pred)**2)\n",
    "ESS = np.sum((y_pred - y_bar)**2)\n",
    "assert(abs(TSS - ESS - RSS) < 0.0000001) # check to make sure they are equal\n",
    "\n",
    "print('TSS: \\t{:6.2f}'.format(TSS))\n",
    "print('ESS: \\t{:6.2f}'.format(ESS))\n",
    "print('RSS: \\t{:6.2f}'.format(RSS))\n",
    "print('RMSE:\\t{:6.2f}'.format(np.sqrt(ols_model.mse_resid)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Leverage and Cook's Distance\n",
    "\n",
    "Up to now, we have only looked at regression models with normally distributed noise. But, in the real world there are errors that can be considered outliers in data. These outliers can have greater or lesser effect on the regression line, depending on how extreme they are and their placement with respect to the other data.\n",
    "\n",
    "You can imagine a regression line as a lever. Outliers that occur near the ends of the lever will have a greater influence all other factors being equal. One way to measure influence of a data point is **Cook's distance**. The actual calculation is not so important, but the important thing to know is that Cook's distance measures how sensitive the regression coefficients are to any particular data point, and they do so by measuring how much the coefficients would change if we *remove* that data point.\n",
    "\n",
    "Here's an example of fitting a model with an without a particular data point."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = sim_data.sample(20).reset_index(drop = True)\n",
    "sample.iloc[0, [0, 1]] = (0.0, 5.0) # introduce an outlier\n",
    "sns.scatterplot(x = 'x', y = 'y', data = sample)\n",
    "sns.scatterplot(x = [0], y = [5], color = 'red');\n",
    "\n",
    "x = sample['x']\n",
    "\n",
    "ols_model = sm.ols(formula = 'y ~ x', data = sample)\n",
    "ols_model = ols_model.fit() # fit the model\n",
    "sns.lineplot(x = x, y = ols_model.predict(x), color = 'green', label = 'all data')\n",
    "\n",
    "ols_model = sm.ols(formula = 'y ~ x', data = sample.drop(index = 0))\n",
    "ols_model = ols_model.fit() # fit the model\n",
    "sns.lineplot(x = x, y = ols_model.predict(x), color = 'red', label = 'all data except outlier');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can imagine, using Cook's distance can be very computationally expensive if we have a large data set. We used a small sample of the original data in the above example because otherwise the difference would be insignificant unless the data has lots of serious outliers. To check for that we can just check to see how closely the residuals follow a normal distribution. Serious deviations from the normal distribution can be a problem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outlier_linear = sm.ols(formula = 'y ~ x', data = sim_data).fit()\n",
    "y_outlier = outlier_linear.predict(sim_data['x'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "residuals = outlier_linear.resid\n",
    "statsmodels.qqplot(residuals, stats.norm, fit = True, line = '45')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise\n",
    "\n",
    "We saw how we can use Cook's distance to see how sensitive our model's coefficients are to individual data points. A more wholistic approach we can take for this is by retraining the same model many many times, each time using a **bootstrap sample** of the original data `sim_data`. We can then plot the original regression line and all the bootstrap regression lines to see how much the regression line **wiggles** around.\n",
    "\n",
    "You will need to do the following in one cell:\n",
    "\n",
    "- Fit a linear regression to `sim_data` and plot the scatter plot and the fitted line (in red).\n",
    "- Using 100 iterations, do the following:\n",
    "  - Resample the data with replacement (keeping the original number of rows).\n",
    "  - Fit a linear regression to the bootstrap sample and obtain the predictions.\n",
    "  - Overlay the bootstrap regression lines on the scatter plot. You can do this by just calling `sns.lineplot` every time, and let `alpha = 0.1` so the lines have some transparency."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## your code goes here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### End of exercise"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In general, with $p$ features $X_1, \\cdots, X_p$ the mathematics is mostly unchanged (but we lose the ability to visually see the model). Geometrically, the above equation (minus the error term) describes a $p-$dimensional **hyperplane**:\n",
    "\n",
    "$$Y = \\beta_0 + \\beta_1 X_1 + \\cdots + \\beta_p X_p + \\text{error}$$\n",
    "\n",
    "where the terms $X_j$ could refer to main effects, polynomial effects or interaction terms.\n",
    "\n",
    "We want to avoid having too many features that are highly correlated among each other. We refer to this as the problem of **multi-collinearity**, and it can result in unstable predictions and **over-fitting**.\n",
    "\n",
    "## Visualizing the effect of interaction terms\n",
    "\n",
    "We finish this notebook with an example to help you build an intuitive understanding of what interaction terms do for a linear regression model. Say you have two variables $X_1$ and $X_2$ and are having to choose between the model with main effects only $Y \\approx \\beta_1 X_1 + \\beta_2 X_2$ or the full model with the interaction term $Y \\approx \\beta_1 X_1 + \\beta_2 X_2 + \\beta_{12}X_1X_2$. To help visualize the difference between the two models, we start by generating some data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "beta_0 = -5 # the intercept\n",
    "beta_1 = 2 # the slope\n",
    "beta_2 = 3\n",
    "beta_12 = 1\n",
    "\n",
    "x_1 = np.linspace(0, 1, num = 200) # np.random.uniform(0, 20, size = 200)\n",
    "x_2 = np.linspace(0, 1, num = 200) # np.random.uniform(0, 20, size = 200)\n",
    "error = np.random.normal(0, 1, size = 200)\n",
    "y_data = beta_0 + beta_1 * x_1 + beta_2 * x_2 + beta_12 * x_1 * x_2 + error\n",
    "\n",
    "sim_data = pd.DataFrame({'X_1': x_1, 'X_2': x_2, 'Y': y_data})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's now train a model that only considers main effects, using `Y ~ X_1 + X_2` as the formula for `sm.ols`. Once the model is fit, we make predictions for `Y` and we plot the scatter plot of $X_1$ and $Y$ along with the prediction line in red. We then fix the values of $X_2$ to some integer and predict $Y$ again, using a blue line to show the predictions. We repeat this incrementing the integer we fix $X_2$ each time and making the shade of blue slightly lighter every time. What results is the plot below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ols_model = sm.ols(formula = 'Y ~ X_1 + X_2', data = sim_data).fit()\n",
    "sim_data['Y_pred'] = ols_model.predict(sim_data)\n",
    "\n",
    "sns.scatterplot(x = 'X_1', y = 'Y', data = sim_data)\n",
    "sns.lineplot(x = 'X_1', y = 'Y_pred', color = 'red', data = sim_data)\n",
    "\n",
    "for i, ii in enumerate(np.linspace(0, 1, num = 50)):\n",
    "    sim_data['X_2'] = ii\n",
    "    sim_data['Y_pred_fix'] = ols_model.predict(sim_data)\n",
    "    sns.lineplot(x = 'X_1', y = 'Y_pred_fix', color = 'blue', data = sim_data, alpha = (1/(i + 1))**0.7);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can ignore the points on the plots and just focus on the lines. The pattern we see suggests that one way to intuit about a model with main effects only is that if we slice the prediction hyperplane at some dimension ($X_2$ in our example), then we expect the prediction at the slice to be a hyperplane with one fewer dimension, and the only difference between any two slices is the \"height\" of the line in the $Y$ dimension. Of course, this is just a different way to describe a hyperplane.\n",
    "\n",
    "Let's now train a model that only considers main effects, using `Y ~ X_1 + X_2` as the formula for `sm.ols`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ols_model = sm.ols(formula = 'Y ~ X_1 * X_2', data = sim_data).fit()\n",
    "sim_data['Y_pred'] = ols_model.predict(sim_data)\n",
    "\n",
    "sns.scatterplot(x = 'X_1', y = 'Y', data = sim_data)\n",
    "sns.lineplot(x = 'X_1', y = 'Y_pred', color = 'red', data = sim_data)\n",
    "\n",
    "for i, ii in enumerate(np.linspace(0, 1, num = 50)):\n",
    "    sim_data['X_2'] = ii\n",
    "    sim_data['Y_pred_fix'] = ols_model.predict(sim_data)\n",
    "    sns.lineplot(x = 'X_1', y = 'Y_pred_fix', color = 'blue', data = sim_data, alpha = (1/(i + 1))**0.7);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now see that the points follow the prediction line, not surprising since that's how the we generated the data. In this new pattern, the prediction at a given slice of $X_2$ is a hyperplane with one fewer dimension where any two slices can have a diiferent slope in the $X_1 \\times Y$ space. This means the surface spanned by the equation is not a hyperplane anymore, but a curved surface that looks like a **saddle**. Adding an $X_1^2$ and $X_2^2$ term opens us to other possibile surfaces."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "So we saw how linear regression takes the concept of hypothesis testing and applies it to the prediction problem. Prediction problems are called **supervised learning** in ML terminology. As we will later see, the family of linear regression models are just one type of prediction algorithm, but in terms of importance they are the most important one as many more sophisticated algorithms such as neural networks build opon the simple ideas presented here. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment\n",
    "\n",
    "In this assignment, we develop on the ideas of linear regression we learned in the lecture to train multiple linear regression models and compare them. Recall that the HSB2 data contains students' scores in five different subjects."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib\n",
    "matplotlib.rcParams['figure.figsize'] = [10, 7]\n",
    "import scipy.stats as stats\n",
    "import matplotlib.pyplot as plt\n",
    "import statsmodels.api as statsmodels\n",
    "import statsmodels.formula.api as sm\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error, r2_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>read</th>\n",
       "      <th>write</th>\n",
       "      <th>math</th>\n",
       "      <th>science</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>57</td>\n",
       "      <td>52</td>\n",
       "      <td>41</td>\n",
       "      <td>47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>68</td>\n",
       "      <td>59</td>\n",
       "      <td>53</td>\n",
       "      <td>63</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>44</td>\n",
       "      <td>33</td>\n",
       "      <td>54</td>\n",
       "      <td>58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>63</td>\n",
       "      <td>44</td>\n",
       "      <td>47</td>\n",
       "      <td>53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>47</td>\n",
       "      <td>52</td>\n",
       "      <td>57</td>\n",
       "      <td>53</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   read  write  math  science\n",
       "0    57     52    41       47\n",
       "1    68     59    53       63\n",
       "2    44     33    54       58\n",
       "3    63     44    47       53\n",
       "4    47     52    57       53"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hsb2 = pd.read_csv('./hsb2.csv')\n",
    "X = hsb2[['read', 'write', 'math', 'science']]\n",
    "Y = hsb2['socst']\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Use the reading, writing, math and science scores to predict a student's score in social studies. Train your model using `LinearRegression` in `sklearn`. Add the model's predictions to the data as a new column called `socst_pred_skl`. <span style=\"color:red\" float:right>[5 point]</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "students_model = LinearRegression()\n",
    "students_model.fit(X, Y)\n",
    "hsb2['socst_pred_skl'] = students_model.predict(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Train the same model a second time, but this time use `sm.ols` in `statsmodels` to do it. Add the model's predictions to the data as a new column called `socst_pred_ols`. <span style=\"color:red\" float:right>[3 point]</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "sim_data = pd.DataFrame({'read': X['read'], 'write': X['write'], 'math': X['math'], 'science': X['science'], 'socst': Y})\n",
    "\n",
    "ols_model = sm.ols(formula = 'socst ~ read + write + math + science', data = sim_data).fit()\n",
    "hsb2['socst_pred_ols'] = ols_model.predict(sim_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Check that the predictions from the two models are the same. <span style=\"color:red\" float:right>[1 point]</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>female</th>\n",
       "      <th>race</th>\n",
       "      <th>ses</th>\n",
       "      <th>schtyp</th>\n",
       "      <th>prog</th>\n",
       "      <th>read</th>\n",
       "      <th>write</th>\n",
       "      <th>math</th>\n",
       "      <th>science</th>\n",
       "      <th>socst</th>\n",
       "      <th>socst_pred_skl</th>\n",
       "      <th>socst_pred_ols</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>70</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>57</td>\n",
       "      <td>52</td>\n",
       "      <td>41</td>\n",
       "      <td>47</td>\n",
       "      <td>57</td>\n",
       "      <td>52.526194</td>\n",
       "      <td>52.526194</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>121</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>68</td>\n",
       "      <td>59</td>\n",
       "      <td>53</td>\n",
       "      <td>63</td>\n",
       "      <td>61</td>\n",
       "      <td>60.480348</td>\n",
       "      <td>60.480348</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>86</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>44</td>\n",
       "      <td>33</td>\n",
       "      <td>54</td>\n",
       "      <td>58</td>\n",
       "      <td>31</td>\n",
       "      <td>41.859538</td>\n",
       "      <td>41.859538</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>141</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>63</td>\n",
       "      <td>44</td>\n",
       "      <td>47</td>\n",
       "      <td>53</td>\n",
       "      <td>56</td>\n",
       "      <td>52.434954</td>\n",
       "      <td>52.434954</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>172</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>47</td>\n",
       "      <td>52</td>\n",
       "      <td>57</td>\n",
       "      <td>53</td>\n",
       "      <td>61</td>\n",
       "      <td>50.666603</td>\n",
       "      <td>50.666603</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    id  female  race  ses  schtyp  prog  read  write  math  science  socst  \\\n",
       "0   70       0     4    1       1     1    57     52    41       47     57   \n",
       "1  121       1     4    2       1     3    68     59    53       63     61   \n",
       "2   86       0     4    3       1     1    44     33    54       58     31   \n",
       "3  141       0     4    3       1     3    63     44    47       53     56   \n",
       "4  172       0     4    2       1     2    47     52    57       53     61   \n",
       "\n",
       "   socst_pred_skl  socst_pred_ols  \n",
       "0       52.526194       52.526194  \n",
       "1       60.480348       60.480348  \n",
       "2       41.859538       41.859538  \n",
       "3       52.434954       52.434954  \n",
       "4       50.666603       50.666603  "
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hsb2.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Print the model summary from the model we trained with `sm.ols`. The formula uses a format similar to `Y ~ X_1 + X_2`. Interpret the model's coefficients and write a few brief sentences about what the model is telling us. <span style=\"color:red\" float:right>[5 point]</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:                  socst   R-squared:                       0.477\n",
      "Model:                            OLS   Adj. R-squared:                  0.466\n",
      "Method:                 Least Squares   F-statistic:                     44.49\n",
      "Date:                Wed, 23 Mar 2022   Prob (F-statistic):           1.65e-26\n",
      "Time:                        00:45:20   Log-Likelihood:                -693.15\n",
      "No. Observations:                 200   AIC:                             1396.\n",
      "Df Residuals:                     195   BIC:                             1413.\n",
      "Df Model:                           4                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "Intercept      7.2060      3.611      1.995      0.047       0.084      14.328\n",
      "read           0.3808      0.080      4.759      0.000       0.223       0.539\n",
      "write          0.3752      0.080      4.669      0.000       0.217       0.534\n",
      "math           0.1322      0.089      1.487      0.139      -0.043       0.308\n",
      "science       -0.0279      0.079     -0.352      0.725      -0.185       0.129\n",
      "==============================================================================\n",
      "Omnibus:                        6.177   Durbin-Watson:                   1.932\n",
      "Prob(Omnibus):                  0.046   Jarque-Bera (JB):                6.368\n",
      "Skew:                          -0.428   Prob(JB):                       0.0414\n",
      "Kurtosis:                       2.827   Cond. No.                         691.\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n"
     ]
    }
   ],
   "source": [
    "print(ols_model.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This prints out a very nice summary table about our model we trained. First we see that the dep variable was indeed 'socst' like we wanted. We see the moethod as 'least squares', as intended. We see there were 200 observations, and 195 degrees of freedom due to us having 5 parameters. We see R-squared values of approximately 0.47 to 0.48, which means that the model is accounting for about 48% of the variance of the data. Prob (F-statistic) is 1.65e-26 so we can reject our Null hypothesis that the model explains nothing and there is no correlation between the dependent and independent variables. Onto the variables; notice the P > |t| column which is basically the same as a p-value. First we see the math and science rows have much higher values here than the others and even to the point where we would say that there is no special relaionship between a student's math and science scores and their social studies scores. This is also supported by the fact that for both science and math, 0 is within both confidence intervals. Now the read and write variables have very small p-values (like smaller than 0.001) which means we should reject the null (for these variables specifically) and that they are really relevant to a student's social studies score. Finally we have the 'intercept' variable which represents the entire model. We see that the p-value for the model is 0.047, therefore the model should have some success predicting social studies scores based on their other test scores."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Find the model's coefficents using the closed-form solution for linear regression:  <span style=\"color:red\" float:right>[3 point]</span>\n",
    "\n",
    "$${b} = ({X'}{X})^{-1}{X'}{Y}$$ \n",
    "\n",
    "To make it easy, we have created a matrix `M` which is the matrix $X$ with an extra column of 1s for the intercept term. Make sure the results match what's reported in the above model summary. HINT: You can use `np.linalg.inv` to invert a matrix, `np.matmul` to multiply two matrices, and the `transpose()` method to take the transpose of a matrix. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 7.2060275   0.38075199  0.37518056  0.13222368 -0.02794164]\n"
     ]
    }
   ],
   "source": [
    "M = np.concatenate([np.ones(len(Y)).reshape(-1, 1), X.values], axis = 1)\n",
    "M[:5, :]\n",
    "\n",
    "b_1 = np.matmul(np.transpose(M), M)\n",
    "b_2 = np.matmul(np.transpose(M), Y)\n",
    "b = np.matmul(np.linalg.inv(b_1), b_2)\n",
    "\n",
    "print(b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- The `fit` method used by `sm.ols` has an argument called `normalize`. Use it to train the same model but using the normalized features instead. What changes do you notice in the model summary? <span style=\"color:red\" float:right>[2 point]</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "# not required, will check it out though"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NOTE: We say that ordinary least squares is **invariant to normalization**, while other methods we learn later such as lasso or ridge regression are not.\n",
    "\n",
    "- Train a new model with `sm.ols` but this time only include the reading and writing scores as features. Decide if you should use a model *with or without* interactions. HINT: Change the formula from `Y ~ X_1 + X_2` to `Y ~ X_1 * X_2` and the new model will estimate the main effects $\\beta_\\text{read}$ and $\\beta_\\text{write}$ and their interaction $\\beta_\\text{read:write}$. <span style=\"color:red\" float:right>[2 point]</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:                  socst   R-squared:                       0.471\n",
      "Model:                            OLS   Adj. R-squared:                  0.466\n",
      "Method:                 Least Squares   F-statistic:                     87.78\n",
      "Date:                Wed, 23 Mar 2022   Prob (F-statistic):           5.53e-28\n",
      "Time:                        00:56:18   Log-Likelihood:                -694.29\n",
      "No. Observations:                 200   AIC:                             1395.\n",
      "Df Residuals:                     197   BIC:                             1404.\n",
      "Df Model:                           2                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "Intercept      8.5575      3.377      2.534      0.012       1.897      15.218\n",
      "read           0.4237      0.068      6.268      0.000       0.290       0.557\n",
      "write          0.4115      0.073      5.627      0.000       0.267       0.556\n",
      "==============================================================================\n",
      "Omnibus:                        7.918   Durbin-Watson:                   1.954\n",
      "Prob(Omnibus):                  0.019   Jarque-Bera (JB):                8.093\n",
      "Skew:                          -0.493   Prob(JB):                       0.0175\n",
      "Kurtosis:                       3.004   Cond. No.                         458.\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n"
     ]
    }
   ],
   "source": [
    "ols_model_rw = sm.ols(formula = 'socst ~ read + write', data = sim_data).fit()\n",
    "\n",
    "print(ols_model_rw.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on running the above cell with different 'formula' arguments dictating if the model is with or without interaction, I conclude that with interaction is better than without interaction. Both models wind up with very similar R-squared values, but that is about the only relevant similarity. The F-statistic is about an order of magnitude smaller without interaction, though both are well below 0.05. Obviously there's a difference of 1 for the degrees of freedom since the with interaction model has an extra parameter 'read:write'. Now for the parameters, we see that both read and write have p-values that are well below the threshold of 0.05 as well as having standard errors much smaller than the coefficient estimates (good sanity check), but when compared to the with-interaction read and write parameters we see values well above the threshold for statistical significance (0.428 and 0.381). The intercept parameter's p-value isn't quite below the threshold, however it is much better than it's with-interaction counterpart (0.012 vs 0.381). Finally, there is just so much that shouts 'this is not a good model' for the with-interaction model, but the final piece is the fact that all of the 95% confidence intervals include 0 which means each parameter is not significant."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- So far we've only had models with numeric features, but it's possible to also include **categorical features**. Add the term `C(prog)` to the formula. This will add the feature `prog` to the model as a categorical feature. This feature states which of 3 after-school program a student participated in. <span style=\"color:red\" float:right>[2 point]</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = hsb2[['read', 'write', 'math', 'science', 'prog']]\n",
    "sim_data = pd.DataFrame({'read': X['read'], 'write': X['write'], 'math': X['math'], 'science': X['science'], 'prog': X['prog'], 'socst': Y})\n",
    "\n",
    "ols_model_prog = sm.ols(formula = 'socst ~ read + write + C(prog)', data = sim_data).fit()\n",
    "hsb2['socst_pred_w/ C(prog)'] = ols_model.predict(sim_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Report the important results in the model summary. <span style=\"color:red\" float:right>[5 point]</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:                  socst   R-squared:                       0.495\n",
      "Model:                            OLS   Adj. R-squared:                  0.485\n",
      "Method:                 Least Squares   F-statistic:                     47.78\n",
      "Date:                Wed, 23 Mar 2022   Prob (F-statistic):           5.84e-28\n",
      "Time:                        00:48:00   Log-Likelihood:                -689.69\n",
      "No. Observations:                 200   AIC:                             1389.\n",
      "Df Residuals:                     195   BIC:                             1406.\n",
      "Df Model:                           4                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "================================================================================\n",
      "                   coef    std err          t      P>|t|      [0.025      0.975]\n",
      "--------------------------------------------------------------------------------\n",
      "Intercept       13.4029      3.755      3.569      0.000       5.997      20.809\n",
      "C(prog)[T.2]     1.9098      1.431      1.335      0.184      -0.912       4.732\n",
      "C(prog)[T.3]    -2.5976      1.612     -1.612      0.109      -5.776       0.581\n",
      "read             0.3780      0.068      5.528      0.000       0.243       0.513\n",
      "write            0.3583      0.074      4.845      0.000       0.212       0.504\n",
      "==============================================================================\n",
      "Omnibus:                        6.641   Durbin-Watson:                   1.943\n",
      "Prob(Omnibus):                  0.036   Jarque-Bera (JB):                6.837\n",
      "Skew:                          -0.449   Prob(JB):                       0.0328\n",
      "Kurtosis:                       2.881   Cond. No.                         527.\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n"
     ]
    }
   ],
   "source": [
    "print(ols_model_prog.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The summary looks very similar to the previous one. The differences I noticed first were that there are now 2 more parameters, which slightly confuses me since there are 3 possible values for the new categorical variable, however maybe you only need n-1 parameters for a given category with n possibilities (?) not sure. Those 2 extra parameters appear to be on their face pretty useless (both their 95% confidence intervals straddle 0), however due to the fact that out model's intercept parameter's p-value is even smaller now than before I don't know that we can conclude that they are indeed useless. The coefficients for both read and write are slightly smaller, but the error is the same size, which is really intriguing. Also, the fact that the C(prog)[T.3] coefficient is -2.5976 is very interseting to me, since all the other coefficients are positive."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# End of assignment"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "235.05px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
